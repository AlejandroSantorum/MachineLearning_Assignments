{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datos import Datos\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta,abstractmethod\n",
    "\n",
    "\n",
    "class Clasificador:\n",
    "\n",
    "    # Clase abstracta\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    # Metodos abstractos que se implementan en casa clasificador concreto\n",
    "    @abstractmethod\n",
    "    # TODO: esta funcion debe ser implementada en cada clasificador concreto\n",
    "    # datosTrain: matriz numpy con los datos de entrenamiento\n",
    "    # atributosDiscretos: array bool con la indicatriz de los atributos nominales\n",
    "    # diccionario: array de diccionarios de la estructura Datos utilizados para la codificacion de variables discretas\n",
    "    def entrenamiento(self,datosTrain,atributosDiscretos,diccionario):\n",
    "        pass\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    # TODO: esta funcion debe ser implementada en cada clasificador concreto\n",
    "    # devuelve un numpy array con las predicciones\n",
    "    def clasifica(self,datosTest,atributosDiscretos,diccionario):\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Obtiene el numero de aciertos y errores para calcular la tasa de fallo\n",
    "    # TODO: implementar\n",
    "    def error(self,datos,pred):\n",
    "        # Aqui se compara la prediccion (pred) con las clases reales y se calcula el error\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Realiza una clasificacion utilizando una estrategia de particionado determinada\n",
    "    # TODO: implementar esta funcion\n",
    "    def validacion(self,particionado,dataset,clasificador,seed=None):\n",
    "        # Creamos las particiones siguiendo la estrategia llamando a particionado.creaParticiones\n",
    "        # - Para validacion cruzada: en el bucle hasta nv entrenamos el clasificador con la particion de train i\n",
    "        # y obtenemos el error en la particion de test i\n",
    "        # - Para validacion simple (hold-out): entrenamos el clasificador con la particion de train\n",
    "        # y obtenemos el error en la particion test. Otra opci�n es repetir la validaci�n simple un n�mero especificado de veces, obteniendo en cada una un error. Finalmente se calcular�a la media.\n",
    "        pass\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "class ClasificadorNaiveBayes(Clasificador):\n",
    "\n",
    "    # TODO: implementar\n",
    "    def entrenamiento(self,datostrain,atributosDiscretos,diccionario):\n",
    "        # First we calculate the priors.\n",
    "        [ndata, nfeat] = datostrain.shape\n",
    "        P = []\n",
    "        for j in range(len(diccionario[nfeat-1])):\n",
    "            cont = 0\n",
    "            for i in range(ndata):\n",
    "                cont = cont + (diccionario[nfeat-1].get(datostrain[i][nfeat-1]) == j)\n",
    "            P.append(cont/ndata)\n",
    "            \n",
    "        # Now we calculate the conditional probabilities.\n",
    "        CP = np.zeros((len(diccionario[nfeat-1]), nfeat-1, 3))\n",
    "\n",
    "        for i in range (len(diccionario[nfeat-1])):\n",
    "            for j in range (nfeat-1):\n",
    "                cont = 0\n",
    "                for l in range(len(diccionario[j])):\n",
    "                    for k in range(ndata):\n",
    "                        if(diccionario[nfeat-1].get(dataset.datos[k][nfeat-1]) == i):\n",
    "                            cont = cont + (dataset.diccionario[j].get(dataset.datos[k][j]) == l)\n",
    "                    CP[i][j][l] = cont/ndata\n",
    "            \n",
    "\n",
    "\n",
    "    # TODO: implementar\n",
    "    def clasifica(self,datostest,atributosDiscretos,diccionario):\n",
    "        Pred = []\n",
    "        [ndata, nfeat] = datostest.shape\n",
    "        for i in range (ndata):\n",
    "            auxpred = []\n",
    "            for k in range(len(diccionario[nfeat - 1])):\n",
    "                aux = P[k]\n",
    "                for j in range (nfeat-1):\n",
    "                    aux = aux * CP[j][diccionario[j].get(datostest[i][j])][k]\n",
    "                auxpred.append(aux)\n",
    "            Pred.append(auxpred.index(max(auxpred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASO DISCRETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Datos(\"../ConjuntosDatos/tic-tac-toe.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "958 10\n",
      "[True, True, True, True, True, True, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "[ndata, nfeat] = dataset.datos.shape\n",
    "print(ndata,nfeat)\n",
    "print(dataset.nominalAtributos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'negative': 0, 'positive': 1}\n"
     ]
    }
   ],
   "source": [
    "print ((dataset.diccionario[nfeat-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3465553235908142, 0.6534446764091858]\n"
     ]
    }
   ],
   "source": [
    "P = []\n",
    "for j in range(len(dataset.diccionario[nfeat-1])):\n",
    "    cont = 0\n",
    "    for i in range(ndata):\n",
    "        cont = cont + (dataset.diccionario[nfeat-1].get(dataset.datos[i][nfeat-1]) == j)\n",
    "    P.append(cont/ndata)\n",
    "    \n",
    "print (P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.18975904 0.22683706]\n",
      "  [0.62951807 0.52875399]\n",
      "  [1.         1.        ]]\n",
      "\n",
      " [[0.23493976 0.27476038]\n",
      "  [0.53915663 0.64057508]\n",
      "  [1.         1.        ]]\n",
      "\n",
      " [[0.18975904 0.22683706]\n",
      "  [0.62951807 0.52875399]\n",
      "  [1.         1.        ]]\n",
      "\n",
      " [[0.23493976 0.27476038]\n",
      "  [0.53915663 0.64057508]\n",
      "  [1.         1.        ]]\n",
      "\n",
      " [[0.14457831 0.17891374]\n",
      "  [0.72289157 0.41533546]\n",
      "  [1.         1.        ]]\n",
      "\n",
      " [[0.23493976 0.27476038]\n",
      "  [0.53915663 0.64057508]\n",
      "  [1.         1.        ]]\n",
      "\n",
      " [[0.18975904 0.22683706]\n",
      "  [0.62951807 0.52875399]\n",
      "  [1.         1.        ]]\n",
      "\n",
      " [[0.23493976 0.27476038]\n",
      "  [0.53915663 0.64057508]\n",
      "  [1.         1.        ]]\n",
      "\n",
      " [[0.18975904 0.22683706]\n",
      "  [0.62951807 0.52875399]\n",
      "  [1.         1.        ]]]\n"
     ]
    }
   ],
   "source": [
    "nvals = 3\n",
    "CP = np.zeros((nfeat-1, nvals, len(dataset.diccionario[nfeat-1])))\n",
    "\n",
    "for i in range (len(dataset.diccionario[nfeat-1])):\n",
    "    for j in range (nfeat-1):\n",
    "        cont = 0\n",
    "        for l in range(len(dataset.diccionario[j])):\n",
    "            for k in range(ndata):\n",
    "                if(dataset.diccionario[nfeat-1].get(dataset.datos[k][nfeat-1]) == i):\n",
    "                    cont = cont + (dataset.diccionario[j].get(dataset.datos[k][j]) == l)\n",
    "            CP[j][l][i] = cont/(ndata*P[i])\n",
    "print (CP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "Pred = []\n",
    "for i in range (ndata):\n",
    "    auxpred = []\n",
    "    for k in range(len(dataset.diccionario[nfeat - 1])):\n",
    "        aux = P[k]\n",
    "        for j in range (nfeat-1):\n",
    "            aux = aux * CP[j][dataset.diccionario[j].get(dataset.datos[i][j])][k]\n",
    "        auxpred.append(aux)\n",
    "    Pred.append(auxpred.index(max(auxpred)))\n",
    "print(Pred)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASO CONTINUO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Datos(\"../ConjuntosDatos/german.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 21\n",
      "[True, False, True, True, False, True, True, False, True, True, False, True, False, True, True, False, True, False, True, True, False]\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "[ndata, nfeat] = dataset.datos.shape\n",
    "print(ndata,nfeat)\n",
    "print(dataset.nominalAtributos)\n",
    "print ((dataset.diccionario[nfeat-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = []\n",
    "m2 = []\n",
    "M = np.zeros((nfeat - 1, 2))\n",
    "V = np.zeros((nfeat - 1, 2))\n",
    "for j in range (nfeat - 1):\n",
    "    if (dataset.nominalAtributos[j] == False):\n",
    "        # We calculate the mean coditioned to each possible class\n",
    "        for i in range(ndata):\n",
    "            if (dataset.datos[i][nfeat-1] == 1):\n",
    "                m1.append(dataset.datos[i][j])\n",
    "            if(dataset.datos[i][nfeat-1] == 2):\n",
    "                m2.append(dataset.datos[i][j])\n",
    "        M[j][0] = np.mean(m1)\n",
    "        V[j][0] = np.var(m1)\n",
    "        M[j][1] = np.mean(m2)\n",
    "        V[j][1] = np.var(m2)\n",
    "        \n",
    "        # We calculate the variance conditioned to each possible class\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.            0.        ]\n",
      " [  19.20714286   24.86      ]\n",
      " [   0.            0.        ]\n",
      " [   0.            0.        ]\n",
      " [1502.33214286 1981.49333333]\n",
      " [   0.            0.        ]\n",
      " [   0.            0.        ]\n",
      " [1002.52809524 1322.02777778]\n",
      " [   0.            0.        ]\n",
      " [   0.            0.        ]\n",
      " [ 752.60678571  992.23333333]\n",
      " [   0.            0.        ]\n",
      " [ 609.33028571  800.57933333]\n",
      " [   0.            0.        ]\n",
      " [   0.            0.        ]\n",
      " [ 508.01261905  667.37722222]\n",
      " [   0.            0.        ]\n",
      " [ 435.6044898   572.20238095]\n",
      " [   0.            0.        ]\n",
      " [   0.            0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00]\n",
      " [1.22581378e+02 1.75840400e+02]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [5.07913627e+06 1.00586731e+07]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [3.88569944e+06 7.57557208e+06]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [3.10165687e+06 6.00797248e+06]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [2.56346399e+06 4.95332811e+06]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [2.18754640e+06 4.21648749e+06]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [1.90649741e+06 3.66848166e+06]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(V)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
